{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02-Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (27,67,70,71) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>...</th>\n",
       "      <th>crosspost_parent_list</th>\n",
       "      <th>removed_by_category</th>\n",
       "      <th>media</th>\n",
       "      <th>media_embed</th>\n",
       "      <th>secure_media</th>\n",
       "      <th>secure_media_embed</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>poll_data</th>\n",
       "      <th>edited</th>\n",
       "      <th>link_flair_css_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>coioteatomico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_7w0v95ej</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>PiratusInteruptus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_3sett0rm</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Manawisp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Pothos</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_z7j6n</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>youdontknowmemessy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_10d88scc</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>mroebuilds</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_78cpyr3d</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_awardings  allow_live_comments              author  \\\n",
       "0            []                False       coioteatomico   \n",
       "1            []                False   PiratusInteruptus   \n",
       "2            []                False            Manawisp   \n",
       "3            []                False  youdontknowmemessy   \n",
       "4            []                False          mroebuilds   \n",
       "\n",
       "   author_flair_css_class author_flair_richtext author_flair_text  \\\n",
       "0                     NaN                    []               NaN   \n",
       "1                     NaN                    []               NaN   \n",
       "2                     NaN                    []            Pothos   \n",
       "3                     NaN                    []               NaN   \n",
       "4                     NaN                    []               NaN   \n",
       "\n",
       "  author_flair_type author_fullname author_patreon_flair author_premium  ...  \\\n",
       "0              text     t2_7w0v95ej                False          False  ...   \n",
       "1              text     t2_3sett0rm                False          False  ...   \n",
       "2              text        t2_z7j6n                False          False  ...   \n",
       "3              text     t2_10d88scc                False          False  ...   \n",
       "4              text     t2_78cpyr3d                False          False  ...   \n",
       "\n",
       "  crosspost_parent_list  removed_by_category  media  media_embed secure_media  \\\n",
       "0                   NaN                  NaN    NaN          NaN          NaN   \n",
       "1                   NaN                  NaN    NaN          NaN          NaN   \n",
       "2                   NaN                  NaN    NaN          NaN          NaN   \n",
       "3                   NaN                  NaN    NaN          NaN          NaN   \n",
       "4                   NaN                  NaN    NaN          NaN          NaN   \n",
       "\n",
       "  secure_media_embed author_cakeday poll_data edited  link_flair_css_class  \n",
       "0                NaN            NaN       NaN    NaN                   NaN  \n",
       "1                NaN            NaN       NaN    NaN                   NaN  \n",
       "2                NaN            NaN       NaN    NaN                   NaN  \n",
       "3                NaN            NaN       NaN    NaN                   NaN  \n",
       "4                NaN            NaN       NaN    NaN                   NaN  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in Data\n",
    "data = pd.read_csv('.././data/reddit_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can anyone identify this?</td>\n",
       "      <td>plants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brought mine for the winter</td>\n",
       "      <td>plants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monsters sad. What do I do? North TX</td>\n",
       "      <td>plants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avacado, are these roots? Also how much longer...</td>\n",
       "      <td>plants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My first succulent arrangement! 3 parts soil 2...</td>\n",
       "      <td>plants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>The judgement</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Muffin my latest foster ðŸ˜»ðŸ˜»ðŸ˜»</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NEW VIDEO!! We have a ton of content on IG.. f...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Sleeping Beauty</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Canâ€™t believe itâ€™s been 4 years since I adopte...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title subreddit\n",
       "0                             Can anyone identify this?    plants\n",
       "1                           Brought mine for the winter    plants\n",
       "2                  Monsters sad. What do I do? North TX    plants\n",
       "3     Avacado, are these roots? Also how much longer...    plants\n",
       "4     My first succulent arrangement! 3 parts soil 2...    plants\n",
       "...                                                 ...       ...\n",
       "9995                                      The judgement      cats\n",
       "9996                        Muffin my latest foster ðŸ˜»ðŸ˜»ðŸ˜»      cats\n",
       "9997  NEW VIDEO!! We have a ton of content on IG.. f...      cats\n",
       "9998                                    Sleeping Beauty      cats\n",
       "9999  Canâ€™t believe itâ€™s been 4 years since I adopte...      cats\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I don't need everything that I pulled\n",
    "post_data = data[['title','subreddit']]\n",
    "post_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate RegEx tokenizer\n",
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]')\n",
    "#Run tokenizer\n",
    "tokenized_data = [tokenizer.tokenize(row) for row in data['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-f1755c810f5e>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  post_data['text_lemmatized'] = post_data['title'].apply(lemmatize_text)\n"
     ]
    }
   ],
   "source": [
    "#instantiate tokenizer and lemmatizer, and apply to the title column in the dataframe\n",
    "# function from https://stackoverflow.com/questions/47557563/lemmatization-of-all-pandas-cells\n",
    "# added if statement to remove stop words from the text_lemmatized lists\n",
    "#if w.lower() not in stopwords.words('english') removed so that stop words could be used in model\n",
    "\n",
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    row = [lemmatizer.lemmatize(w) for w in tokenizer.tokenize(text) ]\n",
    "    string = ''\n",
    "    for word in range(len(row)):\n",
    "        string = string + row[word].lower() + ' '\n",
    "    return string\n",
    "post_data['text_lemmatized'] = post_data['title'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can anyone identify this?</td>\n",
       "      <td>plants</td>\n",
       "      <td>can anyone identify this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brought mine for the winter</td>\n",
       "      <td>plants</td>\n",
       "      <td>brought mine for the winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monsters sad. What do I do? North TX</td>\n",
       "      <td>plants</td>\n",
       "      <td>monsters sad what do i do north tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avacado, are these roots? Also how much longer...</td>\n",
       "      <td>plants</td>\n",
       "      <td>avacado are these root also how much longer un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My first succulent arrangement! 3 parts soil 2...</td>\n",
       "      <td>plants</td>\n",
       "      <td>my first succulent arrangement 3 part soil 2 p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>The judgement</td>\n",
       "      <td>cats</td>\n",
       "      <td>the judgement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Muffin my latest foster ðŸ˜»ðŸ˜»ðŸ˜»</td>\n",
       "      <td>cats</td>\n",
       "      <td>muffin my latest foster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NEW VIDEO!! We have a ton of content on IG.. f...</td>\n",
       "      <td>cats</td>\n",
       "      <td>new video we have a ton of content on ig follo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Sleeping Beauty</td>\n",
       "      <td>cats</td>\n",
       "      <td>sleeping beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Canâ€™t believe itâ€™s been 4 years since I adopte...</td>\n",
       "      <td>cats</td>\n",
       "      <td>can t believe it s been 4 year since i adopted...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title subreddit  \\\n",
       "0                             Can anyone identify this?    plants   \n",
       "1                           Brought mine for the winter    plants   \n",
       "2                  Monsters sad. What do I do? North TX    plants   \n",
       "3     Avacado, are these roots? Also how much longer...    plants   \n",
       "4     My first succulent arrangement! 3 parts soil 2...    plants   \n",
       "...                                                 ...       ...   \n",
       "9995                                      The judgement      cats   \n",
       "9996                        Muffin my latest foster ðŸ˜»ðŸ˜»ðŸ˜»      cats   \n",
       "9997  NEW VIDEO!! We have a ton of content on IG.. f...      cats   \n",
       "9998                                    Sleeping Beauty      cats   \n",
       "9999  Canâ€™t believe itâ€™s been 4 years since I adopte...      cats   \n",
       "\n",
       "                                        text_lemmatized  \n",
       "0                             can anyone identify this   \n",
       "1                          brought mine for the winter   \n",
       "2                   monsters sad what do i do north tx   \n",
       "3     avacado are these root also how much longer un...  \n",
       "4     my first succulent arrangement 3 part soil 2 p...  \n",
       "...                                                 ...  \n",
       "9995                                     the judgement   \n",
       "9996                           muffin my latest foster   \n",
       "9997  new video we have a ton of content on ig follo...  \n",
       "9998                                   sleeping beauty   \n",
       "9999  can t believe it s been 4 year since i adopted...  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-bf94fdd679b0>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  post_data['subreddit'] = post_data['subreddit'].map({'plants': 0,'cats':1}).astype(int)\n"
     ]
    }
   ],
   "source": [
    "#binarize the target column\n",
    "post_data['subreddit'] = post_data['subreddit'].map({'plants': 0,'cats':1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can anyone identify this?</td>\n",
       "      <td>0</td>\n",
       "      <td>can anyone identify this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brought mine for the winter</td>\n",
       "      <td>0</td>\n",
       "      <td>brought mine for the winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monsters sad. What do I do? North TX</td>\n",
       "      <td>0</td>\n",
       "      <td>monsters sad what do i do north tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avacado, are these roots? Also how much longer...</td>\n",
       "      <td>0</td>\n",
       "      <td>avacado are these root also how much longer un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My first succulent arrangement! 3 parts soil 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>my first succulent arrangement 3 part soil 2 p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  subreddit  \\\n",
       "0                          Can anyone identify this?          0   \n",
       "1                        Brought mine for the winter          0   \n",
       "2               Monsters sad. What do I do? North TX          0   \n",
       "3  Avacado, are these roots? Also how much longer...          0   \n",
       "4  My first succulent arrangement! 3 parts soil 2...          0   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0                          can anyone identify this   \n",
       "1                       brought mine for the winter   \n",
       "2                monsters sad what do i do north tx   \n",
       "3  avacado are these root also how much longer un...  \n",
       "4  my first succulent arrangement 3 part soil 2 p...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the text_lemmatized column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X and Y and split data\n",
    "X = post_data['text_lemmatized']\n",
    "y = post_data['subreddit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'X_train' (Series)\n",
      "Stored 'X_test' (Series)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/35935670/share-variables-between-different-jupyter-notebooks\n",
    "#storing these variables so I can use them in the next notebook\n",
    "%store X_train X_test y_train y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
